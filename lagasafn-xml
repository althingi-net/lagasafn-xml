#!/usr/bin/env python3
from colorama import Fore
from colorama import Style
from bs4 import BeautifulSoup
import codecs
import json
import re
import roman

import signal
import os
import sys


import settings

from collections import OrderedDict
from formencode.doctest_xml_compare import xml_compare
from lxml import etree
from lxml.builder import E
from sys import stderr

from contenthandlers import check_chapter
from contenthandlers import generate_ancestors
from contenthandlers import next_footnote_sup
from contenthandlers import regexify_markers
from contenthandlers import separate_sentences
from contenthandlers import strip_markers

import diff_patch_utils

from multiprocessing import Pool

from utils import UnexpectedClosingBracketException
from utils import Matcher
from utils import numart_next_nrs
from utils import determine_month
from utils import is_roman
from utils import order_among_siblings
from utils import sorted_law
from utils import strip_links
from utils import super_iter
from utils import terminal_width_and_height
from utils import xml_lists_identical

DATA_DIR = 'data'

LAW_FILENAME = os.path.join(DATA_DIR, 'original', settings.CURRENT_PARLIAMENT_VERSION, '%d%s.html')  # % (law_year, law_num)
CLEAN_FILENAME = os.path.join(DATA_DIR, 'cleaned', '%d-%d.html')  # % (law_year, law_num)
PATCHED_FILENAME = os.path.join(DATA_DIR, 'patched', '%d-%d.html')  # % (law_year, law_num)
PATCH_FILENAME = os.path.join(DATA_DIR, 'patches', settings.CURRENT_PARLIAMENT_VERSION, '%d-%d.html.patch')  # % (law_year, law_num)
XML_FILENAME = os.path.join(DATA_DIR, 'xml', '%d.%s.xml')  # % (law_year, law_num)

ERRORMAP_FILENAME = os.path.join('data', 'json-maps', 'errormap.json')


def clean_content(content):
    # Decode ISO-8859-1 character encoding.

    # content = content.decode('ISO-8859-1')

    # Make sure that horizontal bar tags are closed properly.
    #content = content.replace('<hr>', '<hr />')

    # Make sure that linebreak tags are closed properly.
    #content = content.replace('<br>', '<br />')

    if not settings.FEATURES['PARSE_MARKERS']:
        # Remove markers for previous changes and removed content.
        content = content.replace('[', '').replace(']', '')
        content = content.replace('…', '').replace('&hellip;', '')

    # Remove links to website
    # strings_to_remove = (
    #     'Ferill málsins á Alþingi.',
    #     'Frumvarp til laga.',
    # )
    # for s in strings_to_remove:
    #     content = content.replace(s, '')

    # Make sure that image tags are closed properly.
    #e = re.compile(r'<img ([^>]*)>', re.IGNORECASE)
    #content = e.sub(r'<img \1 />', content)

    # Remove superscript/subscript when ratios are presented in the form of
    # divisions. For example, "3/4" tends to be stylized with a superscripted
    # "3" and a subscripted "4". We'll want to remove such styling because
    # we're only interested in content. Layouting mechanisms will have to
    # stylize them again if needed.
    e = re.compile(
        r'<sup style="font-size:60%">(\d+)</sup>/<span style="font-size:60%">(\d+)</span>'
    )
    content = e.sub(r'\1/\2', content)

    # Remove <a id=""> tags which are unclosed and seem without purpose.
    # For example, see source of page: http://www.althingi.is/altext/143/s/0470.html
    #content = content.replace('<a id="">', '')

    # Remove links to other laws. These are not useful in their current state.
    # Rather, references to other laws, such as "laga nr. XX/XXXX" or "lög nr.
    # XX/XXXX" should be automatically turned into precise references. (This
    # has not been implemented at the time of this writing. Remove this
    # comment when it has been. 2021-06-25)
    e = re.compile(r'<a href="\d{7}.html">(.*?)</a>')
    content = e.sub(r'\1', content)

    # Fix inconsistent deletion markers.
    # TODO: This only occurs in 160/2010 and should be removed once it has
    # been fixed in the data.
    e = re.compile(r'&hellip;<sup>(\d+)\)</sup>')
    content = e.sub(r'&hellip;<sup style="font-size:60%">\1)</sup>', content)

    # Find the law content and exit if it does not exist
    soup_law = BeautifulSoup(content, 'html5lib').find('html')
    if soup_law is None:
        return None

    soup = BeautifulSoup(soup_law.__str__(), 'html5lib')  # Parse the law content

    if not settings.FEATURES['PARSE_MARKERS']:
        # Remove superscripts indicating previous change. Only removes them when
        # they are found outside of footnotes.
        superscripts = soup.find_all('sup')
        for s in superscripts:
            if s.parent.name != 'small' and re.match(r'^\d{1,3}\)$', s.text):
                s.extract()

    # Remove tags entirely irrelevant to content
    # tags_to_remove = ['small'] # Previously also ['hr', 'script', 'noscript', 'head']
    # for target_tag in tags_to_remove:
    #     [s.extract() for s in soup(target_tag)]

    # Remove empty tags, but only if they're empty
    empty_tags_to_remove = ['p', 'h2', 'i']
    for target_tag in empty_tags_to_remove:
        empty_tags = soup.find_all(lambda tag: tag.name == target_tag and not tag.contents and (
            tag.string is None or not tag.string.strip()
        ))
        [empty_tag.extract() for empty_tag in empty_tags]

    # Keep consecutive <br />s only at 2 at most
    brs_in_a_row = 0
    all_tags = soup.find_all()
    for t in all_tags:
        if t.name == 'br':
            if brs_in_a_row >= 2:
                t.extract()
            else:
                brs_in_a_row = brs_in_a_row + 1
        else:
            brs_in_a_row = 0

    # Replace <html> and <body> tags' with <div>s.
    '''
    body_tag = soup.find('body')
    if body_tag is not None:
        body_tag.attrs['id'] = 'body_tag'
        body_tag.name = 'div'
    html_tag = soup.find('html')
    html_tag.attrs['id'] = 'html_tag'
    html_tag.name = 'div'
    '''

    # Add charset tag
    charset_tag = soup.new_tag('meta', charset='utf-8')
    soup.insert(0, charset_tag)

    xhtml = soup.prettify()

    # Final cleanup at text-stage.
    xhtml = xhtml.replace(' <!-- Tab -->\n  ', '&nbsp;&nbsp;&nbsp;&nbsp;')

    return xhtml


def clean_law(law_num, law_year):
    with codecs.open(LAW_FILENAME % (law_year, str(law_num).zfill(3)), 'r', 'ISO-8859-1') as infile:
        raw_content = infile.read()
        infile.close()

    content = clean_content(raw_content)

    if content is None:
        print(' failed.')
        print('Error: Law %d/%d does not seem to exist' % (law_year, law_num))
        quit(1)

    if not os.path.isdir(os.path.dirname(CLEAN_FILENAME)):
        os.mkdir(os.path.dirname(CLEAN_FILENAME))

    with open(CLEAN_FILENAME % (law_year, law_num), 'w') as clean_file:
        clean_file.write(content)
        clean_file.close()


def patch_law(law_num, law_year):
    if not os.path.isdir(os.path.dirname(PATCHED_FILENAME)):
        os.mkdir(os.path.dirname(PATCHED_FILENAME))

    filename = CLEAN_FILENAME % (law_year, law_num)
    patch_path = os.path.join(PATCH_FILENAME % (law_year, law_num))
    patched_content = diff_patch_utils.do_patch(filename, patch_path)
    with open(PATCHED_FILENAME % (law_year, law_num), 'w') as patched_file:
        patched_file.write(patched_content)


def make_xml(law_num, law_year):

    # Make sure that the XML output directory exists.
    if not os.path.isdir(os.path.dirname(XML_FILENAME)):
        os.mkdir(os.path.dirname(XML_FILENAME))

    # Construct the output XML object.
    law = E.law('', {'nr': str(law_num), 'year': str(law_year)})

    # Check if we have a patched cleaned HTML version of the law.
    if os.path.isfile(PATCHED_FILENAME % (law_year, law_num)):
        with open(PATCHED_FILENAME % (law_year, law_num)) as patched_file:
            lines = super_iter(patched_file.readlines())
            patched_file.close()
    else:
        # Open and read the cleaned HTML version of the law.
        with open(CLEAN_FILENAME % (law_year, law_num)) as clean_file:
            lines = super_iter(clean_file.readlines())
            clean_file.close()

    # Keeps track of the turn of events. We can query this list to check for
    # example whether the name of the document has been processed, or what the
    # last thing to be processed was. This gives us context when determining
    # what to do next.
    trail = ['start']

    # See utils.py.
    matcher = Matcher()

    # collect/uncollect functions for collecting heaps of text, then returning it all in one go
    # and resetting the collection for the next time we need to collect a bunch of text.

    def collect(string):
        if not hasattr(collect, 'collection'):
            collect.collection = []
        collect.collection.append(string.strip())

    def uncollect():
        result = ' '.join(collect.collection).strip()
        collect.collection = []
        return result

    # Will collect lines until the given string is found, and then return the
    # collected lines.
    def collect_until(lines, end_string):
        done = False
        while not done:
            line = next(lines).strip()
            if matcher.check(line, end_string):
                done = True
                continue
            collect(line)

        total = uncollect().strip()

        return total

    # Checks how much iteration is required to hit a line that matches the
    # given regex. Optional limit parameter allows limiting search to a specific
    # number of lines into the future.
    def occurrence_distance(lines, regex, limit=None):
        # We start at +1 to avoid matching the current line.
        i = 1
        line = lines.peek(i)
        while line is not None and (limit is None or i <= limit):
            line = line.strip()
            if matcher.check(line, regex):
                return i

            i += 1
            line = lines.peek(i)

        return None

    # Scrolls the lines until the given string is found. It works internally
    # the same as the collect_until-function, but is provided here with a
    # different name to provide a semantic distinction in the code below.
    scroll_until = collect_until

    # Objects that help us figure out the current state of affairs. These
    # variables are used between iterations, meaning that whenever possible,
    # their values should make sense at the end of the processing of a
    # particular line or clause. Never put nonsense into them because it will
    # completely confuse the processing elsewhere.
    chapter = None
    art = None
    subart = None
    numart = None

    # The cleaned document that we're processing is expected to put every tag,
    # both its opening and closing, on a separate line. This allows us to
    # browse the HTML contents on a per-line basis.
    for line in lines:
        line = line.strip()

        if line == '<h2>':
            # Parse law name.
            name = collect_until(lines, '</h2>')

            law.append(E.name(name))

            trail.append('name')

        elif line == '<strong>':
            if trail[-1] == 'name':
                # Parse the num and date, which appears directly below the law name.
                num_and_date = collect_until(lines, '</strong>')

                # The num-and-date tends to contain excess whitespace.
                num_and_date = num_and_date.replace('  ', ' ')

                # Find the law's number, if it is specified, as well as the
                # location of the date section within the string.
                if 'nr.' in num_and_date:
                    # Note: len('1980 nr. ') == 9
                    number = num_and_date[9:num_and_date.find(' ', 9)]

                    # Note: len(' ') == 1
                    date_start = 9 + len(number) + 1
                else:
                    number = None

                    # Note: len('1980 ') == 5
                    date_start = 5

                # Example: "6. júní"
                human_date = num_and_date[date_start:]

                # Parse the date in its entirety.
                year = int(num_and_date[0:4])
                if human_date.find('.') > -1:
                    day = int(human_date[0:human_date.find('.')])
                    month = int(determine_month(human_date[len(str(day)) + 2:]))
                else:
                    # There is at least one case of a the timing of the
                    # enacted law only being designated by year and month, but
                    # without a day. In these cases, human_date should simply
                    # be the name of the month.
                    # Example: https://www.althingi.is/lagas/148c/1764000.html
                    day = 0
                    month = int(determine_month(human_date)) if human_date else 0

                # Produce an ISO-formatted date.
                iso_date = '%04d-%02d-%02d' % (year, month, day)

                # Construct the XML node and add it to the main doc.
                xml_num_and_date = E('num-and-date', E('date', iso_date))
                if number is None:
                    # If no law number is specified, then the one defined in
                    # the main XML document is actually not a law number, but
                    # a concatenation of date elements, for example 61/1847
                    # for January 6th, 1847.
                    #
                    # Here we correct for the mistaken data, so that instead
                    # of being wrong, the law number will be "m01d06" where
                    # "m" stands for month and "d" stands for day. Note that
                    # the output of the script will still say "61/1847"
                    # instead of "m01d06/1847" because we can't know this
                    # until we've parsed the data this far.
                    #
                    # We will still retain the wrong legal number as
                    # "primitive-nr" for traceability.
                    law.attrib['primitive-nr'] = str(law_num)
                    law_num = 'm%02dd%02d' % (month, day)
                    law.attrib['nr'] = law_num
                else:
                    # Otherwise, of course, we'll just record the number.
                    xml_num_and_date.append(E('num', number))

                xml_num_and_date.append(E('original', num_and_date))

                law.append(xml_num_and_date)

                trail.append('num-and-date')

        # This condition is a bit of a mess because on occasion, the name of
        # the law has been changed, but the footnotes describing them reside
        # inside what we normally call minister-clause. In other words, we
        # need to parse the contents of the minister-clause for footnotes.
        # Luckily, the footnotes to the name change always come first inside
        # the minister-clause, so what we need to do is to exclude the
        # footnotes-part of the minister-clause. We do this by checking for
        # the conditions of a minister-clause in two separate way, one for the
        # normal circumstance where there are no footnotes inside it, and also
        # in another way which corresponds with how the HTML looks when
        # footnotes are present.
        #
        # First, it checks the normal way, which is for the first <hr/> tag
        # after the law number and date, but **not** starting to read it as
        # the minister-clause **if** the second next tag is a <small>, because
        # that indicates that before the regular minister-clause content comes
        # up, there will be some footnotes that we'll want processed
        # elsewhere. When that happens, we will not process the content as a
        # minister-clause, but will rather pass this time, and let the
        # footnote-processing mechanism pick it up.
        #
        # Second, it checks if we have hit an indication that the previously
        # mentioned footnotes-inside-minister-clause part has indeed been
        # picked up elsewhere is over, and that we should conclude that we've
        # started processing the traditional minister-clause content after
        # such footnote-processing. This is done in a way that is not
        # abundantly clear by just reading the code. It just so happens that
        # under the circumstance that a law's name has changed and a footnote
        # appears inside the minister-clause to describe it, that we'll run
        # into "</small></i><br/>" and this seems consistent. However, that
        # pattern of tags can appear in many other circumstances as well. So
        # what we do, is that we check for that pattern, but only match it if
        # we haven't already processed the minister-clause. The way that this
        # is indicated is if "intro-finished" is in the processing trail. As a
        # result, we check for that pattern, but only match if we haven't yet
        # finished "intro-finished".
        #
        # TODO: Consider creating a specified function for this check. It is
        # ridiculously messy as is.
        elif (
            line == '<hr/>' and trail[-1] == 'num-and-date' and lines.peek(2).strip() != '<small>'
        ) or (
            line == '<br/>' and lines.peek(-1).strip() == '</i>' and
            lines.peek(-2).strip() == '</small>' and 'intro-finished' not in trail
        ):
            # Parse the whole clause about which minister the law refers to.
            # It contains HTML goo, but we'll just let it float along. It's
            # not even certain that we'll be using it, but there's no harm in
            # keeping it around.

            # If there is no <hr/> clause in the future, it means that there
            # is no minister clause.
            hr_distance = occurrence_distance(lines, '<hr/>')
            if hr_distance is not None and hr_distance > 0:
                minister_clause = collect_until(lines, '<hr/>')
                if len(minister_clause):
                    law.append(E('minister-clause', minister_clause))

            trail.append('intro-finished')

        # Chapters are found by finding a <b> tag that comes right after a
        # <br/> tag that occurs after the ministerial clause is done. We use a
        # special function for this because we also need to examine a bit of
        # the content which makes the check more than a one-liner.
        elif check_chapter(lines, law) == 'chapter' and 'intro-finished' in trail:
            # Parse what we will believe to be a chapter.

            # Chapter names are a bit tricky. They may be divided into two <b>
            # clauses, in which case the former one is what we call a nr-title
            # (I. kafli, II. kafli etc.), and then a name describing its
            # content (Almenn ákvæði, Tilgangur og markmið etc.).
            #
            # Sometimes however, there is only one <b> and not two. In these
            # cases, there is no nr-title and only a name.
            #
            # To solve this, we first collect the content between the first
            # <b> and </b> and store that in a variable called
            # `name_or_nr_title` because we still don't know whether it's a
            # chapter name or a chapter nr-title. If however, a <b> is found
            # immediately following it, we conclude that what we've gathered
            # is the chapter nr-title and that the content in the next <b>
            # clause will be the chapter name.

            name_or_nr_title = collect_until(lines, '</b>')

            if lines.peek().strip() == '<b>':
                chapter_nr_title = name_or_nr_title

                # Let's see if we can figure out the number of this chapter.
                # We're going to assume the format "II. kafli" for the second
                # chapter, and "II. kafli B." for the second chapter B, and in
                # those examples, nr-titles will be "2" and "2b" respectively.
                t = strip_markers(chapter_nr_title).strip()
                maybe_nr = t[0:t.index('.')]
                try:
                    nr = str(roman.fromRoman(maybe_nr))
                    roman_nr = maybe_nr
                    nr_type = 'roman'
                except roman.InvalidRomanNumeralError:
                    nr = int(maybe_nr)
                    roman_nr = None
                    nr_type = 'arabic'

                # We assume that a chapter nr-title with an alphabetical
                # character (like "II. kafli B" or "2b") can only occur in
                # chapters that contain the word "kafli". This is by
                # necessity, because we need to be able to parse chapter names
                # like "II. Nefndir." which contain a Roman numeral and name.
                # A chapter name like "II B. Nefndir" looks pretty outlandish
                # though, so this should be safe. Instead, the legislature
                # would surely name the chapter to "II. kafli B. Nefndir".
                #
                # We check for both "kafli" and other words known to also
                # designate some kind of chapter, because those are logically
                # equivalent, but should never appear both in the same chapter
                # line.
                for chapter_word_check in ['kafli', 'hluti', 'bók']:
                    if chapter_word_check in t:
                        alpha = t[t.index(chapter_word_check) + 6:].strip('.')
                        if alpha:
                            nr += alpha.lower()
                del t

                scroll_until(lines, '<b>')
                chapter_name = collect_until(lines, '</b>')

                chapter = E.chapter(
                    {'nr': str(nr), 'nr-type': nr_type},
                    E('nr-title', chapter_nr_title),
                    E('name', chapter_name)
                )

                # Record the original Roman numeral if applicable.
                if roman_nr is not None:
                    chapter.attrib['roman-nr'] = roman_nr

            else:
                chapter_name = name_or_nr_title

                # When the chapter doesn't have both a nr-title and a name,
                # what we see may be either a name or a Roman numeral. If it's
                # a Roman numeral, we'll want to do two things; 1) Include the
                # number in the "nr" attribute (in Arabic) and 2) Use the
                # "nr-title" tag instead of the "name" tag. If it's not a
                # Roman numeral, we'll just set a name.
                #
                # Chapters with no name but a Roman numeral may be marked
                # either with the Roman numeral alone, like "IX.", or they may
                # include the word "kafli", looking like "IX. kafli.". We
                # remove the string ". kafli" in the nr-title so that we're
                # always just dealing with the Roman numeral itself when
                # looking for a nr-title.
                try:
                    maybe_roman_nr = strip_markers(chapter_name).replace(
                        '. kafli',
                        ''
                    ).replace(
                        '. hluti',
                        ''
                    ).replace(
                        '. bók',
                        ''
                    ).strip().strip('.')

                    # check for possible roman number range numbering which are seen when multiple
                    # articles have been removed and are thus collectively empty
                    has_ranged_roman = False
                    if '–' in maybe_roman_nr:
                        maybe_roman_nr_a, maybe_roman_nr_b = maybe_roman_nr.split('–')
                        maybe_roman_nr_a = maybe_roman_nr_a.strip('.')
                        if is_roman(maybe_roman_nr_a) and is_roman(maybe_roman_nr_b):
                            nr_a = roman.fromRoman(maybe_roman_nr_a)
                            nr_b = roman.fromRoman(maybe_roman_nr_b)
                            nr = '%s-%s' % (nr_a, nr_b)
                            roman_nr = '%s-%s' % (roman.toRoman(nr_a), roman.toRoman(nr_b))
                            chapter = E.chapter(
                                {'nr': nr, 'nr-type': 'roman', 'roman-nr': maybe_roman_nr},
                                E('nr-title', chapter_name)
                            )
                            has_ranged_roman = True
                    if has_ranged_roman is False:
                        nr = str(roman.fromRoman(maybe_roman_nr))
                        chapter = E.chapter(
                            {'nr': nr, 'nr-type': 'roman', 'roman-nr': maybe_roman_nr},
                            E('nr-title', chapter_name)
                        )
                except roman.InvalidRomanNumeralError:
                    # Nope! It's a name.
                    nr = None
                    chapter = E.chapter(
                        {'nr-type': 'name'},
                        E('name', chapter_name)
                    )

            # Some laws have a chapter for temporary clauses, which may be
            # named something like "Bráðabirgðaákvæði", "Ákvæði til
            # bráðabirgða" and probably something else as well. We will assume
            # that a chapter name that includes that string "bráðabirgð" is a
            # chapter for temporary clauses. We also make a number of other
            # tests on the chapter name to account for various special cases
            # as pointed out in comments below.
            cn = chapter_name.lower()
            if (
                'bráðabirgð' in cn and 'úrræði' not in cn and (
                    # Various places where something has been removed and
                    # commented in content with an a-node.
                    'úrelt ákvæði til bráðabirgða' not in cn or
                    # Special case in 87/1992 where text is before a-node
                    cn.find('ákvæði til bráðabirgða.') == 0
                ) and
                # Special case in law 90/1989
                'brottfallin lög' not in cn and
                # Special case in law 80/2007
                'bráðabirgðaafnot' not in cn
            ):
                if nr is None:
                    chapter.attrib['nr'] = 't'
                chapter.attrib['type'] = 'temporary-clauses'

            law.append(chapter)

            trail.append('chapter')

        elif check_chapter(lines, law) in ['extra-docs', 'appendix'] and 'intro-finished' in trail:
            # Accompanying documents vary in origin and format, and are not a
            # part of the formal legal text itself, even though legal text may
            # reference them. Parsing them is beyond the scope of this tool.
            # They always show up at the end, so at this point, our work is
            # done. We'll escape the loop and go for post-processing.
            break

        elif check_chapter(lines, law) == 'ambiguous' and 'intro-finished' in trail:
            # Parse a mysterious text that might be a chapter but we're unable
            # to determine it as such. They are bold, they are bad, but they
            # don't really make an awful lot of sense. We'll just splash them
            # in as ambiguous bold text and leave it at that.
            #
            # This occurs before the table in 96. gr. laga nr. 55/1991, in
            # version 151b, although the table was removed in version 151c.
            #
            # It happens quite a bit, and like `ambiguous-section`, should
            # theoretically be replaced by something more formal at some
            # point, should the format of published law ever allow.

            ambiguous_bold_text = E('ambiguous-bold-text', collect_until(lines, '</b>'))

            if subart is not None:
                subart.append(ambiguous_bold_text)
            elif art is not None:
                art.append(ambiguous_bold_text)
            elif chapter is not None:
                chapter.append(ambiguous_bold_text)
            else:
                law.append(ambiguous_bold_text)

            trail.append('ambiguous-bold-text')

        elif line == '<em>' and 'intro-finished' in trail:
            # Parse a mysterious thing which we will call an "ambiguous
            # section" and is composed of a single italic line. Such a line is
            # sometimes used as a sort of name for an article (45/1987,
            # 113/1990, 57/1990), sometimes as some kind of subchapter
            # (93/1933, 8/1962, 46/1980) and even as some kind of chapter
            # (37/1992, 55/1992). It is practically impossible to figure out
            # what exactly they are supposed to be, even for humans. Even
            # within the same document they may seem like article names in one
            # place but then seem to cover a few in a latter part. Sometimes
            # they are numbered, sometimes they have letters, sometimes
            # neither, and sometimes both in the same document.
            #
            # The most convoluted known use of such ambiguous sections is
            # 31/1993, where they are apparently used as sub-subchapters
            # numbered with an uppercase Latin letter for each article,
            # meaning that they can be seen as either letter-numbered article
            # names or sub-subchapters.
            #
            # At any rate, we're not going to try and figure it out and place
            # them inside articles (like article names) or articles inside
            # them (like chapters), but instead include them as independent
            # <ambiguous-section>s, leaving the same ambiguity in the XML as
            # is apparent in the actual text. They are rarely, if ever, used
            # to specify a change by a bill anyway, and thus are probably not
            # significant for programming bills in the future. Furthermore,
            # when parsing the XML, it is possible to check what the last
            # <ambiguous-section> contained, if at some point a programmer
            # needs to deal with them when using the XML.
            ambiguous_content = collect_until(lines, '</em>')

            ambiguous_section = E('ambiguous-section', ambiguous_content)

            if chapter is not None:
                chapter.append(ambiguous_section)
            else:
                law.append(ambiguous_section)

            trail.append('ambiguous-section')

        elif line == '<i>' and lines.peek(2).strip() == '</i>' and 'intro-finished' in trail:
            # Parse a sentence with a title. These are rare, but occur in 3.
            # gr. laga nr. 55/2009. Usually they are numbered, parsed as
            # numarts instead, but not here.

            # In 3. gr. laga nr. 55/2009, sentences with titles have the
            # opening marks located right before the <i> tag, meaning that we
            # have no proper place to put it in. We'll place it in the
            # beginning of the sen-title instead. There can be more than one,
            # so we'll append continuously until we run out of opening marks.

            sen_title = ''
            back_peek = lines.peek(-1).strip()
            while len(back_peek) > 0 and back_peek[-1] == '[':
                sen_title += '['
                back_peek = back_peek[0:-1]

            sen_title += collect_until(lines, '</i>')
            sens = collect_until(lines, '<br/>')
            if subart is not None:
                subart.append(E('sen-title', sen_title))
                for sen in separate_sentences(sens):
                    subart.append(E('sen', sen))

                trail.append('sen-with-title')

        elif matcher.check(line, r'<img .+ src=".*sk.jpg" .+\/>'):
            # Parse an article.
            scroll_until(lines, '<b>')
            art_nr_title = collect_until(lines, '</b>')

            clean_art_nr_title = strip_markers(art_nr_title)

            # Hopefully this stays None. Not because anything will break
            # otherwise, but because Roman numerals suck ass.
            art_roman_nr = None

            # Analyze the displayed article name.
            try:
                # A typical article is called something like "13. gr." or
                # "13. gr. b". The common theme among typical articles is that
                # the string ". gr." will appear in them somewhere. Anything
                # before it is the article number. Anything after it, is an
                # extra thing which is appended to article names when new
                # articles are placed between two existing ones. For example,
                # if there already are articles 13 and 14 but the legislature
                # believes that a new article properly belongs between them,
                # the article will probably be called "13. gr. a". We would
                # want that translated into an sortable `art_nr` f.e. "13a".

                # Find index of common string. If the string does not exist,
                # it's some sort of a special article. A ValueError will be
                # raised and we'll deal with it below.
                gr_index = clean_art_nr_title.index('. gr.')

                # Determine the numeric part of the article's name.
                art_nr = clean_art_nr_title[0:gr_index]

                # Occasionally an article number actually covers a range, so
                # far only seen when multiple articles have been removed and
                # are thus collectively empty. We check for the pattern here
                # and reconstruct it if needed.
                if matcher.check(clean_art_nr_title, r'(\d+)\.–(\d+)'):
                    from_art_nr, to_art_nr = matcher.result()
                    art_nr = '%s-%s' % (from_art_nr, to_art_nr)

                # Check if there is an extra part to the name which we'll want
                # appended to the `art_nr`.
                #
                # Note: len('.gr.') + 1 = 6
                art_nr_extra = clean_art_nr_title[gr_index + 6:].strip().strip('.')
                if len(art_nr_extra):
                    art_nr = '%s%s' % (art_nr, art_nr_extra)

            except ValueError:
                # This means that the article's name is formatted in an
                # unconventional way. Typically this occurs only in temporary
                # clauses that tend to be numbered with some stupid fucking
                # Roman bullshit.
                art_nr = clean_art_nr_title.strip('.')
                try:
                    art_roman_nr = str(roman.fromRoman(art_nr))
                except roman.InvalidRomanNumeralError:
                    # Good. Fuck Roman numerals.

                    # Another possibility is that it's a really old-school way
                    # of denoting articles (early 19th century and before),
                    # which looks like "5)" instead of "5. gr.".
                    if matcher.check(art_nr, r'^\d+\)$'):
                        art_nr = art_nr.strip(')')
                    else:
                        # At this point we've run into some kind of article
                        # that we don't know how to deal with yet. We'll just
                        # move on.
                        #
                        # TODO: To investigate what kind of article numbers
                        # are still not supported, an exception could be
                        # thrown here and the script run with options
                        # "-a -e -E":
                        #     raise Exception(
                        #         "Can't figure out: %s" % clean_art_nr_title
                        #     )
                        pass

            # Create the tags, configure them and append to the chapter.
            art = E('art', E('nr-title', art_nr_title))
            art.attrib['nr'] = art_nr
            if art_roman_nr is not None:
                art.attrib['roman-nr'] = art_roman_nr
                art.attrib['number-type'] = 'roman'

            # Some laws don't have chapters, but some do.
            if chapter is not None:
                chapter.append(art)
            else:
                law.append(art)

            # Check if the next line is an <em>, because if so, then the
            # article has a name title and we need to grab it. Note that not
            # all articles have names.
            if lines.peek().strip() == '<em>':
                scroll_until(lines, '<em>')
                art_name = collect_until(lines, '</em>')

                art.append(E('name', strip_links(art_name)))

            # Another way to denote an article's name is by immediately
            # following it with bold text. This is very rare but does occur.
            elif (
                lines.peek().strip() == '<b>' and
                lines.peek(2).strip() != 'Ákvæði til bráðabirgða.'
            ):
                # Exceptional case: 94/1996 contains a very strange temporary
                # clause chapter. It was originally a temporary article (24.
                # gr.) with a name denoted differently than other articles in
                # that bill. It was not a chapter.
                #
                # See: https://www.althingi.is/altext/120/s/0751.html
                #
                # Then the temporary clauses were altered with law that
                # assumed that the temporary clause section was, in fact, a
                # chapter and not an article. This has resulted in an
                # ambiguity, leaving the legal document itself in unparsable
                # limbo. The temporary clauses that are current are not
                # denoted as temporary per se, but rather as strangely
                # numbered articles that appear after article 24, which is
                # still called "Temporary clauses" (in Icelandic) and is
                # technically empty.
                #
                # See: https://www.althingi.is/lagas/150b/1996094.html
                #
                # Before this block of code was written (for supporting
                # article names denoted by <b> tags), we would parse this as a
                # temporary chapter and not as an article, due to the fact
                # that it contains the word "bráðabirgða". Now that we're
                # implementing support for bold-denoted article names, it is
                # parsed as an article name, resulting in the same limbo state
                # that can be found in the official documents.
                #
                # We need to decide whether we wish to imitate the chaotic
                # limbo in the legal code, or to parse the temporary clauses
                # as a chapter and leave article 24 as, in effect, empty.
                #
                # We have decided the latter, for the following reasons:
                #
                # 1. It is clear that Parliament's most recent treatment of
                #    these clauses have assumed that they belonged to a
                #    temporary clause chapter, and not an article. This is
                #    clear from how bills have treated the clauses after the
                #    original bill was passed.
                #
                # 2. The temporary articles are denoted with Roman numerals,
                #    typical of articles in temporary chapters but otherwise
                #    not known to occur to denote temporary clauses.
                #
                # 3. The purpose of this script is to create a logical and
                #    coherent collection of Icelandic law. To imitate the
                #    limbo would go against this goal, whereas interpreting it
                #    as a chapter brings us closer to achieving it.
                #
                # This decision manifests itself in the latter part of the
                # elif-line above, where we peek 2 lines into the future and
                # check if it's the article with that specific name. That
                # latter part only returns true in the very specific case
                # outlined here.

                scroll_until(lines, '<b>')
                art_name = collect_until(lines, '</b>')

                art.append(E('name', strip_links(art_name), {'original-ui-style': 'bold'}))

            # Check if the article is empty aside from markers that need to be
            # included in the article <nr-title> or <name> (depending on
            # whether <name> exists at all).
            while lines.peek().strip() in ['…', ']']:
                marker = collect_until(lines, '</sup>')
                art.getchildren()[-1].text += ' ' + marker + ' </sup>'

            trail.append('art-nr')

            # There can be no current subarticle if we've just discovered a
            # new article.
            subart = None

        elif matcher.check(line, r'<img .+ id="[GB](\d+)[A-Z]?M(\d+)" src=".*hk.jpg" .+\/>'):
            art_nr, subart_nr = matcher.result()

            # Check how far we are from the typical subart end.
            linecount_to_br = occurrence_distance(lines, r'<br/>')

            # Check if there's a table inside the subarticle.
            linecount_to_table = occurrence_distance(lines, r'<\/table>', linecount_to_br)

            # If a table is found inside the subarticle, we'll want to end the
            # subarticle when the table ends.
            if linecount_to_table is not None:
                # We must append the string '</table>' because it gets left
                # behind by the collet_until function.
                content = collect_until(lines, '</table>') + '</table>'
            else:
                # Everyting is normal.
                content = collect_until(lines, '<br/>')

            subart = E('subart', {'nr': subart_nr})
            sens = separate_sentences(strip_links(content))
            for sen in sens:
                subart.append(E('sen', sen))

            # An occasional text, mostly advertisements, declarations, edicts
            # and at least one really ancient law, contain only subarticles.
            # So we'll need to check if there's an article before adding the
            # subart to it. If none exists, we'll check if there's a chapter
            # and if so, we'll append to that. If not, then we'll just string
            # it to the law itself.
            if art is not None:
                art.append(subart)
            elif chapter is not None:
                chapter.append(subart)
            else:
                law.append(subart)

            trail.append('subart')

        elif line.strip() == '…' and trail[-1] == 'intro-finished':
            # Support for a deletion marker before any other content such as
            # an article, subarticle, numart, chapter or anything of the sort.
            # We'll place it in a sentence inside a subart so that the
            # footnotes-functionality responds accordingly.
            #
            # Only known to occur in the following:
            # - m01d13/1736
            # - m07d01/1746
            # - m01d27/1847
            # - 97/1993

            premature_deletion = collect_until(lines, '<br/>')

            sen = E('sen', premature_deletion)
            subart = E('subart', sen)
            subart.attrib['nr'] = '1'

            law.append(subart)

            trail.append('premature-deletion')

        elif matcher.check(line, '<table'):
            # Parse a stray table, that we haven't run across inside a
            # subarticle. We'll append it to previously parsed thing. The
            # table width is only for consistency with the typical input.

            content = '<table width="100%">' + collect_until(lines, '</table>') + '</table>'
            sen = E('sen', separate_sentences(content).pop())

            if subart is not None:
                subart.append(sen)
            elif art is not None:
                art.append(sen)

        elif (
            matcher.check(line, r'<span id="G(\d+)([0-9A-Z]*)L(\d+)">') or
            (matcher.check(line, '<span>') and lines.peek().strip() != '</span>')
        ):
            # The removal of ". " is to turn a human readable numerical
            # article that contains both a numerical component and an
            # alphabetic one, into something easier to work with
            # programmatically. Example: "9. a" becomes "9a" in law nr.
            # 20/2003.
            numart_nr = strip_markers(lines.peek().strip().strip('.')).replace('. ', '')

            # Support for numart ranges, which are only known to occur when
            # many numarts have been removed. This occurs for example in 145.
            # gr. laga nr. 108/2007.
            if matcher.check(numart_nr, r'(\d+)\.–(\d+)'):
                from_numart_nr, to_numart_nr = matcher.result()
                numart_nr = '%s-%s' % (from_numart_nr, to_numart_nr)

            # The previous numart gives us context for decision-making for
            # this numart. It is only filled if the last thing we processed
            # was a numart as well (in trail[-1]), for example whether this is
            # actually a sub-numart or a super-numart. Otherwise it will
            # remain None, indicating that this is the first numart being
            # processed this time around.
            if trail[-1] == 'numart':
                # Set the previous numart before current numart gets created.
                prev_numart = numart
            else:
                prev_numart = None

            # This is only known to happen in 3. gr. laga nr. 160/2010. A
            # numart has been removed and the numbers of its following numarts
            # updated accordingly. We'll just append an empty numart with a
            # special type "removed" and move on, but we need to add it
            # because although it contains no content, it needs to have a
            # container for the deletion marker. That way, the next iteration
            # will make decisions on its context according to this iteration's
            # prev_numart.
            #
            # Its number will be a string, "removed-after-[X]" where "[X]" is
            # the number of the last numart. This is to make them identifiable
            # when rendering software wants to add deletion markers. A "sen"
            # node is also added for the deletion marker to be addable.
            if numart_nr == '':
                content = collect_until(lines, '</span>')
                prev_numart.getparent().append(E(
                    'numart',
                    {
                        'nr': 'removed-after-%s' % prev_numart.attrib['nr'],
                        'type': 'removed'
                    },
                    E('sen', content)
                ))
                scroll_until(lines, '<br/>')
                continue

            # In 6. tölul. 1. gr. laga nr. 119/2018, the removal of previous
            # numarts is communicated differently than above (3. gr. laga nr.
            # 160/2010). In this case, the <span> that normally contains the
            # numart_nr contains nothing, not even the deletion marker
            # (literal string "…"). Instead, the deletion marker comes after
            # the </span> that immediately follows the opening <span>.
            #
            # To deal with it, we will check if the detected numart_nr is
            # "</span>", which makes no sense, check the next line for the
            # deletion marker, and if it's there, we'll respond similarly to
            # how we respond to 3. gr. laga nr. 160/2010 (which was
            # immediately above this comment on 2022-01-23).
            elif numart_nr == '</span>' and lines.peek(2).strip() == '…':
                scroll_until(lines, '</span>')
                content = collect_until(lines, '<br/>')
                prev_numart.getparent().append(E(
                    'numart',
                    {
                        'nr': 'removed-after-%s' % prev_numart.attrib['nr'],
                        'type': 'removed'
                    },
                    E('sen', content)
                ))
                continue

            # Dictates where we will place this numart.
            parent = None

            # The variable `special_roman` is true under the unique
            # circumstances that an alphabetic numart turns from "h" to a new
            # sub-numart with Roman numeral "i", resulting in a sequence of
            # "...f,g,h,i,ii,iii".
            #
            # The varible is used later to prevent the script mistaking the
            # first "i" in a Roman sub-list for the next item in an
            # alpbahetical list.
            #
            # This is tested by checking if the last numart number was "h" but
            # also if exactly 6 lines later, we run into an "ii.", which then
            # means that we've run into a Roman-numeric "i" that would
            # otherwise be mistaken for the letter following "h".
            #
            # NOTE: This is practically a deprecated mechanism but should
            # stlil be retained just in case the same circumstance occurs
            # again in the future. It previously existed in 50. gr. laga nr.
            # 108/2007, which was removed in March of 2020.
            try:
                special_roman = prev_numart.attrib['nr'] == 'h' and lines.peek(6).strip() == 'ii.'
            except (AttributeError, IndexError):
                # Definitely not the special scenario if this goes wrong.
                special_roman = False

            # Build a list of expected numarts. This will help us determine
            # whether this numart is the first among sub-numarts, or if a list
            # of sub-numarts has ended or what.
            if prev_numart is not None:

                # Create a list of expected numart_nrs, considering the type
                # of the previous numart. If the current numart_nr is
                # unexpected, it means that either a sub-numart listing has
                # started, or ended. Whether it's starting or ending, we'll
                # figure out slightly further below.
                expected_numart_nrs = numart_next_nrs(prev_numart)

                # See comment for `special_roman` above. Under the conditions
                # outlined there, we won't be expecting "i" anymore, even if
                # it comes after an "h", and will therefore construct a new
                # sub-list from the "i" after the "h" instead of just adding
                # another item.
                if special_roman:
                    expected_numart_nrs.remove('i')

                if numart_nr not in expected_numart_nrs:
                    if (
                        numart_nr.lower() in ['a', 'i', '—'] or
                        (numart_nr.isdigit() and int(numart_nr) == 1)
                    ):
                        # A new list has started within the one we were
                        # already processing, which we can tell because there
                        # was a `numart` before this one, but this `numart`
                        # says it's at the beginning, being either 'a' or 1.
                        # In this case, we'll choose the previous `numart` as
                        # the parent, so that this new list will be inside the
                        # previous one.
                        parent = prev_numart
                    else:
                        # A different list is being handled now, but it's not
                        # starting at the beginning (is neither 'a' nor 1).
                        # This means that we've been dealing with a sub-list
                        # which has now finished, so we want to continue
                        # appending this `numart` to the parent of the parent
                        # of the list we've been working on recently, which is
                        # the same parent as the nodes that came before we
                        # started the sub-list.
                        parent = prev_numart.getparent().getparent()

                        # When a sub-sub-numart finishes and goes straight up
                        # two levels immediately, (1, 2, a, b, i, ii, 3, 4...)
                        # we'll need the parent to actually be the current
                        # node's grandparent. We'll check this by examining
                        # whether the current numart number is expected to be
                        # the next after the parent's number, since that would
                        # indicate that the parent is really a sibling.
                        if (
                            parent is not None and parent.tag == 'numart' and
                            numart_nr in numart_next_nrs(parent)
                        ):
                            parent = parent.getparent()

                else:
                    # This `numart` is simply the next one, so we'll want to
                    # append it to whatever node that the previous `numart`
                    # was appended to.
                    parent = prev_numart.getparent()

            # A parent may already be set above if `numart` currently being
            # handled is not the first one in its parent article/subarticle.
            # However, if it is indeed the first one, we need to figure out
            # where to place it. It can be placed in a subarticle, an article
            # or, in some cases, into a chapter or even the law itself.
            if parent is None:
                if subart is not None:
                    parent = subart
                elif art is not None:
                    parent = art
                elif chapter is not None:
                    parent = chapter
                else:
                    parent = law

            # Figure out the numart's type.
            if numart_nr[0].isdigit():
                numart_type = 'numeric'
            elif numart_nr == '—':
                numart_type = 'en-dash'
            else:
                # At this point, we're dealing with a numart that is
                # represented with a Latin character, OR a Roman numeral.
                # Because Roman numerals overlap the Latin alphabet, we will
                # need to check the context in which we run into this numart.
                # If it's an "i", we'll need to determine whether it's the
                # alphabetical letter "i" or the Roman numeral "i" for 1, by
                # examining the previous numart. Once we've correctly figured
                # out that difference at the beginning of the list, we can
                # distinguish between Roman numerals and Latin characters by
                # checking the type of the previous numart.

                if numart_nr.lower() == 'i':
                    # See comment for `special_roman` above.
                    if prev_numart is None or prev_numart.attrib['nr'] != 'h' or special_roman:
                        numart_type = 'roman'
                    else:
                        numart_type = 'alphabet'

                elif is_roman(numart_nr.upper()):
                    # If we run into something that *can* be a Roman numeral,
                    # we'll simply inherit the type of the previous numart. We
                    # should never run into these unless there is a previous
                    # numart, since "a" is not a Roman numeral and therefore
                    # we'll only run into overlapping characters once we're
                    # well into the list.
                    #
                    # Note that "i" will always already have been caught by
                    # the previous if-statement before this ever gets the
                    # chance to process it.
                    #
                    # We can't look into the last numart because that may be a
                    # sub-numart of the previous numart. But we're confident
                    # in this numart being the non-first among its siblings,
                    # so we'll know that the parent's last child was the
                    # numart before it. So all we need to do is to find the
                    # last child of this numart's parent to find the one
                    # immediately before it at the same stage in the tree.

                    numart_type = parent.getchildren()[-1].attrib['type']

                else:
                    numart_type = 'alphabet'

            # Create numerical article.
            numart = E('numart', {'nr': numart_nr, 'type': numart_type})

            # Add the numerical article to its parent.
            parent.append(numart)

            numart_nr_title = collect_until(lines, '</span>')
            numart.append(E('nr-title', numart_nr_title))

            if lines.peek().strip() == '<i>':
                # Looks like this numerical article has a name.
                scroll_until(lines, '<i>')
                numart_name = collect_until(lines, '</i>')

                numart.append(E('name', numart_name))

            # Read in the remainder of the content.
            content = collect_until(lines, '<br/>')

            # Split the content into sentences.
            sens = separate_sentences(strip_links(content))

            # Check if this numart is actually just a content-less container
            # for a sub-numart, by checking if the beginning of the content is
            # in fact the starting of a new list, numeric or alphabetic.
            possible_nr_title = strip_markers(sens[0]) if len(sens) else ''
            if possible_nr_title in ['a.', '1.']:
                new_numart_nr = possible_nr_title.strip('.')

                # Instead of adding the found sentences to the numart that
                # we've just made above, we'll create an entirely new numart,
                # called new_numart, and add that to the current numart.
                new_numart = E(
                    'numart',
                    {
                        'nr': new_numart_nr,
                        # The style-note is to communicate information to a
                        # possible layouting mechanism. In the official
                        # documents, a sub-numart that appears this way is not
                        # shown in a new line as normally, but rather inside
                        # its parent as if it were content. It's the layouting
                        # mechanism's responsibility to react to this
                        # information, if needed.
                        'style-note': 'inline-with-parent'
                    },
                    # Note that we go back for the 'sens' list because we'll
                    # want to include markers that might be there, but have
                    # been removed from `possible_nr_title` for comparison
                    # purposes.
                    E('nr-title', sens[0])
                )

                # Mark the new numart as alphabetic, if appropriate.
                if not new_numart_nr.isdigit():
                    new_numart.attrib['type'] = 'alphabet'

                # The first entity in the list will be the nr-title, which
                # we've already used and we don't want in the content, so
                # popped out here.
                sens.pop(0)

                # Add the sentences to the new numart.
                for sen in sens:
                    new_numart.append(E('sen', sen))

                # Add the new numart to the current numart.
                numart.append(new_numart)

                # Make sure that future iterations recognize the new numart as
                # the last one processed.
                numart = new_numart

            else:
                # Add the sentences to the numart.
                for sen in sens:
                    numart.append(E('sen', sen))

            trail.append('numart')

        elif line == '<small>':
            # Footnote section. Contains footnotes.

            footnotes = E('footnotes')

            # Try an append the footnotes to whatever's appropriate given the
            # content we've run into.
            if trail[-1] == 'num-and-date':
                law.append(footnotes)
            elif trail[-1] == 'chapter':
                chapter.append(footnotes)
            elif trail[-1] == 'ambiguous-section':
                ambiguous_section.append(footnotes)
            elif art is not None:
                # Most commonly, footnotes will be appended to articles.
                art.append(footnotes)
            elif subart is not None:
                # In law that don't actually have articles, but only
                # subarticles (which are rare, but do exist), we'll need to
                # append the footnotes to the subarticle instead of the
                # article.
                subart.append(footnotes)

            trail.append('footnotes')

        elif line == '<sup style="font-size:60%">' and trail[-1] in ['footnotes', 'footnote']:
            # We've found a footnote inside the footnote section!

            # Scroll past the closing tag, since we're not going to use its
            # content (see comment below).
            scroll_until(lines, '</sup>')

            # Determine the footnote number.
            # In a perfect world, we should be able to get the footnote number
            # with a line like this:
            #
            #     footnote_nr = collect_until(lines, '</sup>').strip(')')
            #
            # But it may in fact be wrong, like in 149. gr. laga nr. 19/1940,
            # where two consecutive footnotes are numbered as 1 below the
            # article. The numbers are correct in the reference in the article
            # itself, though. For this reason, we'll deduce the correct number
            # from the number of <footnote> tags present in the current
            # <footnotes> tag. That count plus one should be the correct
            # number.
            #
            # The footnote number, and in fact other numbers, are always used
            # as strings because they really function more like names rather
            # than numbers. So we make it a string right away.
            footnote_nr = str(len(footnotes.findall('footnote')) + 1)

            # Create the footnote XML node.
            footnote = E('footnote')

            peek = lines.peek().strip()
            if matcher.check(peek, r'<a href="(\/altext\/.*)">'):
                # This is a footnote regarding a legal change.
                href = 'https://www.althingi.is%s' % matcher.result()[0]

                # Retrieve the the content of the link to the external law
                # that we found.
                scroll_until(lines, r'<a href="(\/altext\/.*)">')
                footnote_sen = collect_until(lines, '</a>')

                # Update the footnote with the content discovered so far.
                footnote.attrib['href'] = href
                footnote.append(E('footnote-sen', footnote_sen))

                # If the content found so far adheres to the recognized
                # pattern of external law, we'll put that information in
                # attributes as well. (It should.)
                if matcher.check(footnote_sen, r'L\. (\d+)\/(\d{4}), (\d+)\. gr\.'):
                    fn_law_nr, fn_law_year, fn_art_nr = matcher.result()
                    footnote.attrib['law-nr'] = fn_law_nr
                    footnote.attrib['law-year'] = fn_law_year
                    footnote.attrib['law-art'] = fn_art_nr

            # Some footnotes don't contain a link to an external law like
            # above but rather some arbitrary information. In these cases
            # we'll need to parse the content differently. But also, sometimes
            # a link to an external law is followed by extra content, which
            # will also be parsed here and included in the footnote.
            #
            # We will gather everything we run across into a string called
            # `gathered`, until we run into a string that indicates that
            # either this footnote section has ended, or we've run across a
            # new footnote. Either one of the expected tags should absolutely
            # appear, but even if they don't, this will still error out
            # instead of looping forever, despite the "while True" condition,
            # because "next(lines)" will eventually run out of lines.
            gathered = ''
            while True:
                if lines.peek().strip() in ['</small>', '<sup style="font-size:60%">']:
                    break
                else:
                    # The text we want is separated into lines with arbitrary
                    # indenting and HTML comments which will later be removed.
                    # As a result, meaningless whitespace is all over the
                    # place. To fix this, we'll remove whitespace from either
                    # side of the string, but add a space at the end, which
                    # will occasionally result in a double whitespace or a
                    # whitespace between tags and content. Those will be fixed
                    # later, resulting in a neat string without any unwanted
                    # whitespace.
                    gathered += next(lines).strip() + ' '

                # Get rid of HTML comments.
                gathered = re.sub(r'<!--.*?"-->', '', gathered)

                # Get rid of remaining unwanted whitespace (see above).
                gathered = gathered.replace('  ', ' ').replace('> ', '>').replace(' </', '</')

            # If extra content was found, we'll put that in a separate
            # sentence inside the footnote. If there already was a
            # <footnote-sen> because we found a link to an external law, then
            # there will be two sentences in the footnote. If this is the only
            # content found and there is no link to an external law, then
            # there will only be this one.
            if len(gathered):
                footnote.append(E('footnote-sen', gathered.strip()))

            # Explicitly state the footnote number as an attribute in the
            # footnote, so that a parser doesn't have to infer it from the
            # order of footnotes.
            footnote.attrib['nr'] = footnote_nr

            # Append the footnote to the `footnotes` node which is expected to
            # exist from an earlier iteration.
            footnotes.append(footnote)

            if lines.peek().strip() == '</small>':
                # At this point, the basic footnote XML has been produced,
                # enough to show the footnotes themselves below each article.
                # We will now see if we can parse the markers in the content
                # that the footnotes apply to, and add marker locations to the
                # footnote XML. We will then remove the markers from the text.
                # This way, the text and the marker location information are
                # separated.

                # The parent is the uppermost node above the footnotes but
                # below the document root node.
                parent = footnotes.getparent()
                while parent.getparent() is not None and parent.getparent() != law:
                    parent = parent.getparent()

                # Closing markers have a tendency to appear after the sentence
                # that they refer to, like so:
                #
                # [Here is some sentence.] 2)
                #
                # This will result in two sentences:
                # 1. [Here is some sentence.
                # 2. ] 2)
                #
                # We'll want to combine these two, so we iterate through the
                # sentences that we have produced and find those that start
                # with closing markers and move the closing markers to the
                # previous sentence. This will make parsing end markers much
                # simpler. If the sentence where we found the closing marker
                # is empty, we'll delete it.
                #
                # In `close_mark_re` we allow for a preceding deletion mark
                # and move that as well, since it must belong to the previous
                # sentence if it precedes the closing marker that clear does.
                # (Happens in 2. mgr. 165. gr. laga nr. 19/1940.)
                close_mark_re = (
                    r'((… <sup style="font-size:60%"> \d+\) </sup>)? ?\]? ?'
                    r'<sup style="font-size:60%"> \d+\) </sup>)'
                )
                nodes_to_kill = []
                for desc in parent.iterdescendants():
                    peek = desc.getnext()

                    # We have nothing to do here if the following node doesn't
                    # exist or contain anything.
                    if peek is None or peek.text is None:
                        continue

                    # Keep moving the closing markers from the next node
                    # ("peek") to the current one ("desc"), until there are no
                    # closing markers in the next node. (Probably there is
                    # only one, but you never know.)
                    while matcher.check(peek.text, close_mark_re):
                        # Get the actual closing marker from the next node.
                        stuff_to_move = matcher.result()[0]

                        # Add the closing marker to the current node.
                        desc.text += stuff_to_move

                        # Remove the closing marker from the next node.
                        peek.text = re.sub(close_mark_re, '', peek.text, 1)

                    # If there's no content left in the next node, aside from
                    # the closing markers that we just moved, then we'll put
                    # the next node on a list of nodes that we'll delete
                    # later. We can't delete it here because it will break the
                    # iteration (parent.iterdescendants).
                    if len(peek.text) == 0:
                        nodes_to_kill.append(peek)

                # Delete nodes marked for deletion.
                for node_to_kill in nodes_to_kill:
                    node_to_kill.getparent().remove(node_to_kill)

                opening_locations = []
                marker_locations = []
                for desc in parent.iterdescendants():
                    # Leave the footnotes out of this, since we're only
                    # looking for markers in text.
                    if 'footnotes' in [a.tag for a in desc.iterancestors()]:
                        continue

                    # Not interested if the node contains no text.
                    if not desc.text:
                        continue

                    ###########################################################
                    # Detection of opening and closing markers, "[" and "]",
                    # respectively, as well as accompanied superscripted text
                    # denoting their number.
                    ###########################################################

                    # Keeps track of where we are currently looking for
                    # markers within the entity being checked.
                    cursor = 0

                    opening_found = desc.text.find('[', cursor)
                    closing_found = desc.text.find(']', cursor)
                    while opening_found > -1 or closing_found > -1:
                        if (
                            opening_found > -1 and
                            (opening_found < closing_found or closing_found == -1)
                        ):
                            # We have found an opening marker: [

                            # Indicate that our next search for an opening tag
                            # will continue from here.
                            cursor = opening_found + 1

                            # Get the ancestors of the node (see function's
                            # comments for details.)
                            ancestors = generate_ancestors(desc, parent)

                            # We now try to figure out whether we want to mark
                            # an entire entity (typically a sentence), or if
                            # we want to mark a portion of it. If we want to
                            # mark a portion, "use_words" shall be True and
                            # the footnote XML will contain something like
                            # this:
                            #
                            #    <sen words="some marked text">2</sen>
                            #
                            # Instead of:
                            #
                            #    <sen>2</sen>
                            #

                            # At this point, the variable `opening_found`
                            # contains the location of the first opening
                            # marker (the symbol "]") in the current node's
                            # text.

                            # Find the opening marker after the current one,
                            # if it exists.
                            next_opening = desc.text.find('[', opening_found + 1)

                            # Check whether the next opening marker, if it
                            # exists, is between the current opening marker
                            # and the next closing marker.
                            no_opening_between = next_opening == -1 or next_opening > closing_found

                            # Use "words" if 1) the opening marker is at the
                            # start of the sentence and 2) there is also a
                            # closing marker found but 3) there's no opening
                            # marker between the current marker and its
                            # corresponding closing marker.
                            partial_at_start = (
                                opening_found == 0 and closing_found > -1 and no_opening_between
                            )

                            # Check if the opening and closing markers
                            # encompass the entire entity. In these cases, it
                            # makes no sense to use "words".
                            all_encompassing = all([
                                opening_found == 0,
                                no_opening_between,
                                desc.text[0] == '[',
                                matcher.check(
                                    desc.text[closing_found:],
                                    r'\] <sup style="font-size:60%"> \d+\) </sup>$'
                                )
                            ])

                            # Boil this logic down into the question: to use
                            # words or not to use words?
                            use_words = (
                                (opening_found > 0 or partial_at_start) and not all_encompassing
                            )

                            if use_words:
                                # We'll start with everything from the opening
                                # marker onward. Because of possible markers
                                # in the text that should end up in "words",
                                # we'll need to do a bit of processing to
                                # figure out where exactly the appropriate
                                # closing marker is located. Quite possibly,
                                # it's not simply the first one.
                                words = desc.text[opening_found + 1:]

                                # Eliminate **pairs** of opening and closing
                                # markers beyond the opening marker we're
                                # currently dealing with. When this has been
                                # accomplished, the next closing marker should
                                # be the one that goes with the opening marker
                                # that we're currently dealing with. Example:
                                #
                                #     a word [and another] that says] boo
                                #
                                # Should become:
                                #
                                #     a word and another that says] boo
                                #
                                # Note that the opening/closing marker pair
                                # around "and another" have disappeared
                                # because they came in a pair. With such pairs
                                # removed, we can conclude our "words"
                                # variable from the remaining non-paired
                                # closing marker, and the result should be:
                                #
                                #     a word and another that says
                                #
                                words = re.sub(
                                    r'\[(.*?)\] <sup style="font-size:60%"> \d+\) </sup>',
                                    r'\1',
                                    words
                                )

                                # Find the first non-paired closing marker.
                                closing_index = words.find(']')

                                # Cut the "words" variable appropriately. If
                                # closing_index wasn't found, it means that
                                # the "words" actually span beyond this
                                # sentence. Instead of cutting the words
                                # string (by -1 because the closing symbol
                                # wasn't found, which would make no sense), we
                                # leave it intact. The rest of the "words"
                                # string will be placed in an <end> element by
                                # the closing-marker mechanism.
                                if closing_index > -1:
                                    words = words[:closing_index]

                                # Explicitly remove marker stuff, even though
                                # most likely it will already be gone because
                                # the marker parsing implicitly avoids
                                # including them. Such removal may leave stray
                                # space that we also clear.
                                words = strip_markers(words).strip()

                                # Add the "words" attribute to the last element.
                                ancestors[-1].attrib['words'] = words

                            # We'll "pop" this list when we find the closing
                            # marker, as per below.
                            opening_locations.append(ancestors)

                        elif (
                            closing_found > -1 and
                            (closing_found < opening_found or opening_found == -1)
                        ):
                            # We have found a closing marker: ]

                            cursor = closing_found + 1

                            # Find the footnote number next to the closing
                            # marker that we've found.
                            num = next_footnote_sup(desc, cursor)

                            # We have figured out the starting location in the
                            # former clause of the if-sentence.
                            try:
                                started_at = opening_locations.pop()
                            except IndexError:
                                # Error: We've run into an unexpected closing
                                # bracket. This happens when Parliament
                                # updates a law, and the changes are marked in
                                # the HTML files, but the corresponding
                                # opening bracket is missing. Typically, a law
                                # is being changed that has already been
                                # changed, and there should be two opening
                                # bracket ("[[") to mark the beginning of a
                                # change to a change, but there is only one
                                # ("[") due to human error.
                                #
                                # Please see the chapter "Patching errors in
                                # data" in the `README.md`.
                                #
                                # This exception spouts some details.
                                raise UnexpectedClosingBracketException(desc)

                            # Get the ancestors of the node (see function's
                            # comments for details.)
                            ancestors = generate_ancestors(desc, parent)

                            # If the start location had a "words" attribute,
                            # indicating that a specific set of words should
                            # be marked, then we'll copy that attribute here
                            # to the end location, so that the <start> and
                            # <end> tags will get truncated into a unified
                            # <location> tag...
                            if 'words' in started_at[-1].attrib:
                                # ...except, if it turns out that we're
                                # actually dealing with a different sentence
                                # than was specified in the start location,
                                # but the "words" attribute is being used, it
                                # means that a string is to be marked that
                                # spans more than one sentence.
                                #
                                # In such a case, the start location will
                                # determine the opening marker via its "words"
                                # attribute, but the end location (being
                                # processed here) will determine the closing
                                # marker with its distinct set of "words",
                                # each attribute containing the set of words
                                # contained in their respective sentences.
                                sen_nr = str(order_among_siblings(desc))
                                if desc.tag == 'sen' and sen_nr != started_at[-1].text:
                                    # Remove pairs of opening/closing markers
                                    # from the "words", so that we find the
                                    # correct closing marker. (See comment on
                                    # same process in processing of opening
                                    # markers above.)
                                    words = re.sub(
                                        r'\[(.*?)\] <sup style="font-size:60%"> \d+\) </sup>',
                                        r'\1',
                                        words
                                    )
                                    words = desc.text[:desc.text.find(']')]
                                else:
                                    words = started_at[-1].attrib['words']

                                ancestors[-1].attrib['words'] = words

                            # Stuff our findings into a list of marker
                            # locations that can be appended to the footnote
                            # XML.
                            marker_locations.append({
                                'num': int(num) if num is not None else None,
                                'type': 'range',

                                # 'started_at' is determined from previous
                                # processing of the corresponding opening
                                # marker.
                                'started_at': started_at,

                                # 'ended_at' is determined from the processing
                                # of the closing marker, which is what we just
                                # performed.
                                'ended_at': ancestors
                            })

                        # Check again for the next opening and closing
                        # markers, except from our cursor, this time.
                        closing_found = desc.text.find(']', cursor)
                        opening_found = desc.text.find('[', cursor)

                    ##########################################################
                    # Detection of deletion markers, indicated by the "…"
                    # character, followed by superscripted text indicating its
                    # reference number.
                    ##########################################################

                    # Keeps track of where we are currently looking for
                    # markers within the entity being checked, like above.
                    cursor = 0

                    deletion_found = desc.text.find('…', cursor)
                    while deletion_found > -1:
                        # Keep track of how far we've already searched.
                        cursor = deletion_found + 1

                        # If the deletion marker is immediately followed by a
                        # closing link tag, it means that this is in fact not
                        # a deletion marker, but a comment. They are not
                        # processed here, so we'll update the deletion_found
                        # variable (in the same way as is done at the end of
                        # this loop) and continue.
                        if desc.text[cursor:cursor + 5] == ' </a>':
                            deletion_found = desc.text.find('…', cursor)
                            continue

                        # Find the footnote number next to the deletion marker
                        # that we've found.
                        num = next_footnote_sup(desc, cursor)

                        # If no footnote number is found, then we're not
                        # actually dealing with a footnote, but rather the "…"
                        # symbol being used for something else. For what,
                        # exactly, is undetermined as of yet.
                        if num is None or num == '':
                            deletion_found = desc.text.find('…', cursor)
                            continue

                        # See function's comments for details.
                        ancestors = generate_ancestors(desc, parent)

                        # len('</sup>') == 6
                        sup_end = desc.text.find('</sup>', deletion_found + 1) + 6

                        # We'll take the text that comes before and after the
                        # deletion mark, and replace their markers with
                        # regular expressions that match them, both with the
                        # markers and without them. This way, any mechanism
                        # intended to put the deletion markers back in works
                        # on the text regardless of whether the other deletion
                        # or replacement markers are already there or not.
                        before_mark = '^' + regexify_markers(desc.text[:deletion_found])
                        after_mark = regexify_markers(desc.text[sup_end:]) + '$'

                        # Deletion markers are styled like this when they
                        # indicate deleted content immediately before a comma:
                        #
                        # "bla bla bla …, 2) yada yada"
                        #
                        # The native text without deletion markers would look
                        # like this:
                        #
                        # "bla bla bla, yada yada"
                        #
                        # We therefore need to check for a comma immediately
                        # following the deletion symbol itself (…). If it's
                        # there, then well communicate the need to add it in
                        # the middle of the deletion marker via the attribute
                        # "middle-punctuation". For possible future
                        # compatibility with other symbols, we'll put in a
                        # comma as the value and expect the marker renderer to
                        # use that directly instead of assuming a comma.
                        if (
                            desc.text[deletion_found + 1:deletion_found + 2] == ',' and
                            before_mark[-1] == ' '
                        ):
                            ancestors[-1].attrib['middle-punctuation'] = ','

                        # Assign the regular expressions for the texts before
                        # and after the deletion mark, to the last node in the
                        # location XML.
                        if before_mark:
                            ancestors[-1].attrib['before-mark'] = before_mark
                        if after_mark:
                            ancestors[-1].attrib['after-mark'] = after_mark

                        marker_locations.append({
                            'num': int(num),
                            'type': 'deletion',
                            'started_at': ancestors
                        })

                        deletion_found = desc.text.find('…', cursor)

                    ##########################################################
                    # Detect single superscripted numbers, which indicate
                    # points that belong to a reference without indicating any
                    # kind of change to the text itself. Such markers will be
                    # called pointers from now on.
                    ##########################################################

                    # Keeps track of where we are currently looking for
                    # pointers within the entity being checked, like above.
                    cursor = 0

                    pointer_found = desc.text.find('<sup style="font-size:60%">', cursor)
                    while pointer_found > -1:
                        # Keep track of how far we've already searched.
                        cursor = pointer_found + 1

                        # See function's comments for details.
                        ancestors = generate_ancestors(desc, parent)

                        # If this is in fact a closing or deletion marker,
                        # then either the symbol "[" or "…" will appear
                        # somewhere among the 3 characters before the
                        # superscript. Their exact location may depend on the
                        # applied styling or punctuation, since spacing style
                        # differs slightly according to the location of
                        # closing and deletion markers, and punctuation can
                        # appear between the symbol and superscript (i.e.
                        # "bla]. 2)".
                        chars_before_start = pointer_found - 3 if pointer_found >= 3 else 0
                        chars_before = desc.text[chars_before_start:pointer_found].strip()
                        if '…' in chars_before or ']' in chars_before:
                            # This is a closing or deletion marker, which
                            # we're not interested in at this point.
                            pointer_found = desc.text.find('<sup style="font-size:60%">', cursor)
                            continue

                        # Catch all the superscript content, so that we may
                        # its length, and while we're at it, grab the footnote
                        # number as well.
                        matcher.check(
                            desc.text[pointer_found:],
                            r'(<sup style="font-size:60%"> (\d+)\) </sup>)'
                        )
                        sup, num = matcher.result()

                        # Determine where the symbol ends.
                        sup_end = pointer_found + len(sup)

                        # We'll take the text that comes before and after the
                        # pointer, and replace their markers with regular
                        # expressions that match them, both with the markers
                        # and without them. This way, any mechanism intended
                        # to put the deletion markers back in works on the
                        # text regardless of whether the other deletion or
                        # replacement markers are already there or not.
                        before_mark = '^' + regexify_markers(desc.text[:pointer_found])
                        after_mark = regexify_markers(desc.text[sup_end:]) + '$'

                        # Assign the regular expressions for the texts before
                        # and after the pointer, to the last node in the
                        # location XML.
                        if before_mark:
                            ancestors[-1].attrib['before-mark'] = before_mark
                        if after_mark:
                            ancestors[-1].attrib['after-mark'] = after_mark

                        marker_locations.append({
                            'num': int(num),
                            'type': 'pointer',
                            'started_at': ancestors
                        })

                        pointer_found = desc.text.find('<sup style="font-size:60%">', cursor)

                    ##########################################################
                    # At this point, we're done processing the following:
                    # 1. Opening/closing markers ("[" and "]")
                    # 2. Deletion markers ("…")
                    # 3. Pointers (indicated by superscripted number)
                    ##########################################################

                    # Now that we're done processing the markers and can add
                    # them to the footnotes in XML format, we'll delete them
                    # from the text itself. This may leave spaces on the edges
                    # which we'll remove as well.
                    desc.text = strip_markers(desc.text).strip()

                # If no marker locations have been defined, we have nothing
                # more to do here.
                if len(marker_locations) == 0:
                    continue

                # Finally, we'll start to build and add the location XML to
                # the footnotes, out of all this information we've crunched
                # from the text!

                # We'll want to be able to "peek" backwards easily, so we'll
                # use the super_iterator. We could also use enumerate() but we
                # figure that using the peek function is more readable than
                # playing around with iterators.
                marker_locations = super_iter(marker_locations)

                for ml in marker_locations:
                    # If the num is None, then the range is not attributable
                    # to a footnote. This occurs in 4. mgr. 10. gr. laga nr.
                    # 40/2007 to indicate that a lowercase letter has been
                    # made uppercase as an implicit result of a legal change
                    # that removed the first portion of the sentence. As far
                    # as we can tell, this is not a rule but rather just the
                    # explanation in that case. Unspecified ranges may
                    # presumably exist for other reasons.
                    #
                    # When this happens, we will respond by adding an
                    # <unspecified-ranges> tag immediately following the
                    # <footnotes> tag that already exists. We will then then
                    # simply stuff the <location> element in there instead of
                    # the footnote that we should find in cases when `num` is
                    # an integer (i.e. referring to a numbered footnote).
                    if ml['num'] is None:
                        # Find the index where we'll want to add the new
                        # <unspecified-ranges> element.
                        new_index = footnotes.getparent().index(footnotes) + 1

                        # Create the new <unspecified-ranges> element.
                        location_target = E('unspecified-ranges')

                        # Add the new element immediately after the
                        # <footnotes> element.
                        footnotes.getparent().insert(new_index, location_target)
                    else:
                        # Get the marker's appropriate footnote XML.
                        location_target = footnotes.getchildren()[ml['num'] - 1]

                    # Create the location XML node itself.
                    location = E('location', {'type': ml['type']})

                    if ml['type'] in ['pointer', 'deletion']:
                        for node in ml['started_at']:
                            location.append(node)

                        location_target.append(location)

                    elif ml['type'] == 'range':
                        # If the starting and ending locations are identical,
                        # we will only want a <location> element to denote the
                        # marker's locations.
                        started_at = ml['started_at']
                        ended_at = ml['ended_at']
                        if xml_lists_identical(started_at, ended_at):
                            for node in started_at:
                                location.append(node)
                        else:
                            # If, however, the the starting and ending
                            # locations differ and we are not denoting a
                            # region of text with "words", we'll need
                            # sub-location nodes, <start> and <end>, within
                            # the <location> element, so that the opening and
                            # closing markers can be placed in completely
                            # different places.
                            start = E('start')
                            end = E('end')
                            for node in started_at:
                                start.append(node)
                            for node in ended_at:
                                end.append(node)

                            location.append(start)
                            location.append(end)

                        # If the location XML that we're adding is identical
                        # to a previous location node in the same footnote
                        # node, then instead of adding the same location node
                        # again, we'll configure the previous one as
                        # repetitive. We assume that if the same words are
                        # marked twice, that all instances of the same words
                        # should be marked in the given element.
                        #
                        # This is done to make it easier to use the XML when
                        # the same set of words should be marked repeatedly in
                        # the same sentence.
                        twin_found = False
                        for maybe_twin in location_target.findall('location'):
                            if xml_compare(maybe_twin, location):
                                maybe_twin.getchildren()[-1].attrib['repeat'] = 'true'
                                twin_found = True
                                break

                        if not twin_found:
                            # Finally, we add the location node to the footnote
                            # node (or unspecified-ranges node).
                            location_target.append(location)

            # Leave a trail saying we're done processing a footnote.
            trail.append('footnote')

    ##########################################################################
    # At this point, the XML object `law` contains the entire document with
    # all its content. Now, we do some post-processing of the already existing
    # content. This is kept separate mostly for reasons of clarity.
    ##########################################################################

    # Turn remaining links which are currently encoded in HTML characters,
    # into XML nodes. Note that most links are filtered out, but some remain,
    # such as those intended as comments. We'll want those to be parsable XML
    # as opposed to text content, so that they can be manipulated by a
    # displaying mechanism, or easily stripped out if needed.
    for node in law.xpath('//sen') + law.xpath('//name'):
        cursor = 0
        html_loc = node.text.find('<a ', cursor)
        while html_loc > -1:
            html_end_loc = node.text.find('</a>', cursor) + len('</a>')

            comment_content = node.text[html_loc:html_end_loc]

            subnode = etree.XML(comment_content)
            text = node.text[0:html_loc].strip()
            tail = node.text[html_end_loc:].strip()

            subnode.text = subnode.text.strip()

            node.text = text
            node.append(subnode)
            subnode.tail = tail

            cursor = html_loc + 1
            html_loc = node.text.find('<a ', cursor)

            del html_end_loc
            del comment_content
            del text
            del tail
            del subnode

        del cursor
        del html_loc

    # Turn HTML tables, currently encoded into HTML characters, into properly
    # structured and clean XML tables with properly presented content.
    #
    # We have no reason to create a table structure different from the HTML
    # structure. We'll just make sure that the data is sanitized properly and
    # that there is no useless information, by recreating the table in XML.
    # This way, it'll be quite easy for a layout engine in a browser to render
    # it correctly.
    for sen in law.xpath('//sen'):
        if sen.text.find('<table ') == 0:

            # The XML table that we are going to produce.
            table = E('table')

            # The HTML table from which we're fetching information.
            html_table = etree.HTML(sen.text).find('body/table/tbody')

            # Find the rows and headers inside the HTML.
            rows = super_iter(html_table)

            # If the table has a header, it will typically be the top row
            # (exception explained below). We'll check the first column of the
            # top row to check whether the headers are designated via <b> tags
            # or <i> tags. If no such tags are found, we are forced to
            # conclude that there is no header. This is also not always true
            # (also explained below).
            #
            # TODO: In temporary clause XII in law nr. 29/1993, tables are
            # found with three rows of headers. These are currently not
            # supported and result in missing data.
            #
            # TODO: In 5. mgr. 19. gr. laga nr. 87/2004, headers are not
            # stylized at all, thereby making them virtually indistinguishable
            # from headers. These are currently unsupported at the moment,
            # meaning they will be interpreted as if they were data cells.
            #
            # TODO: In 96. gr. laga nr. 55/1991, bold and italic items seem to
            # be skipped altogether. This must be the code's fault, somehow.

            toprow = next(rows)
            if toprow[0].find('b') is not None:
                header_style = 'b'
            elif toprow[0].find('i') is not None:
                header_style = 'i'
            else:
                header_style = ''

            # If we've determined that the table has a header at all...
            if header_style:
                thead = E('thead', E('tr'))
                table.append(thead)

                # Add headers to the XML table.
                for col in toprow:
                    header = col.find(header_style).text.strip()
                    if header_style != 'b':
                        # Headers are normally bold, but there are exceptions.
                        # We'll only designate a header style when we run into
                        # an exception to the rule.
                        thead.find('tr').append(E('th', header, {'header-style': header_style}))
                    else:
                        thead.find('tr').append(E('th', header))
            else:
                # Roll one back because we've decided that the first row is
                # not a header after all.
                rows.prev()

            tbody = E('tbody')
            table.append(tbody)

            # Add rows.
            for row in rows:
                tr = E('tr')
                tbody.append(tr)
                for col in row:
                    tr.append(E('td', col.text.strip()))

            # Replace HTML-encoded text with XML table.
            sen.text = None
            sen.append(table)

    # Write the XML object to output file.
    with open(XML_FILENAME % (law_year, law_num), 'w') as f:
        # Importing a completely different XML library than the one we're
        # using elsewhere in the code is a bit weird, but this is the only one
        # we could find that does pretty printing with proper indenting. That
        # happens to be very important for seeing whether the end result
        # works. Since it's only used when DEBUG=True and is very much an
        # anomaly in the code, it is imported here instead of at the top of
        # the file.
        #
        # When not in DEBUG mode, we'll skip those shenanigans and write it
        # out with the same library as the one we use elsewhere.
        if settings.DEBUG:
            import xml.dom.minidom
            xml = xml.dom.minidom.parseString(
                etree.tostring(
                    law,
                    pretty_print=True,
                    xml_declaration=True,
                    encoding='utf-8'
                ).decode('utf-8')
            )
            pretty_xml_as_string = xml.toprettyxml(
                indent='  ',
                encoding='utf-8'
            ).decode('utf-8')
            f.write(pretty_xml_as_string)
        else:
            f.write(
                etree.tostring(
                    law,
                    pretty_print=True,
                    xml_declaration=True,
                    encoding='utf-8'
                ).decode('utf-8')
            )


def process_law(law_id):

    try:

        (law_num, law_year) = law_id.split('/')
        law_num = int(law_num)
        law_year = int(law_year)

        clean_law(law_num, law_year)

        # Delete existing patch file so we don't accidentally have outdated
        # patched files when for example changing to another parliament version.
        patched_path = PATCHED_FILENAME % (law_year, law_num)
        if os.path.isfile(patched_path):
            os.unlink(patched_path)

        # check if we have patch for current law and parliament version
        patch_path = os.path.join(PATCH_FILENAME % (law_year, law_num))
        if os.path.isfile(patch_path):
            # use patch file to create patched version of cleaned file
            patch_law(law_num, law_year)

        try:
            make_xml(law_num, law_year)

        except BaseException:
            # Git is used to monitor success of parsing new versions of the legal
            # codex. When we fail at parsing a document, the accurate
            # representation is the absence of that document.
            try:
                os.remove(XML_FILENAME % (law_year, law_num))
            except FileNotFoundError:
                # This does not matter.
                pass

            # Make sure that this ends up being someone's problem.
            raise

        # Report back that law was processed without error.
        return [law_id, None]

    except Exception:
        # Something went wrong in processing the law, so we'll record the
        # traceback to the errormap.
        import traceback
        lines = ''.join(traceback.format_exception(*sys.exc_info()))

        # Report back which law was attempted to process, and error.
        return [law_id, lines]


def get_available_law_ids():
    law_ids = []
    for filename in os.listdir(os.path.dirname(LAW_FILENAME)):
        if re.match(r'^\d{7}\.html$', filename):
            law_year = int(filename[0:4])
            law_num = int(filename[4:7])
            law_id = '%d/%d' % (law_num, law_year)
            law_ids.append(law_id)
    return law_ids


def get_broken_law_ids():
    law_ids = []

    if os.path.isfile(ERRORMAP_FILENAME):
        with open(ERRORMAP_FILENAME, 'r') as f:
            errormap = json.load(f, object_pairs_hook=OrderedDict)
            for law_id in errormap.keys():
                if errormap[law_id] is not None:
                    law_ids.append(law_id)

    return law_ids


# Displays what's going on to the terminal.
def report(law_id, i, law_count, msg):

    nr = str(i + 1)
    while len(nr) < 4:
        nr = ' %s' % nr

    law_id_str = str(law_id)
    while len(law_id_str) < 8:
        law_id_str = ' %s' % law_id_str

    if msg == 'done':
        color = Fore.GREEN
    elif msg == 'failed':
        color = Fore.RED
    else:
        raise Exception('Unknown message "%s"' % msg)

    print('[%s/%d] %s %s%s%s' % (nr, law_count, law_id_str, color, msg, Style.RESET_ALL))


# Displays errors known according to errormap.
def display_errors(law_ids):
    with open(ERRORMAP_FILENAME, 'r') as f:
        errormap = json.load(f, object_pairs_hook=OrderedDict)

        # Counters.
        failures = 0
        successes = 0

        # The way we want to display this is basically the opposite of
        # how we want to store it. We shall invert the errormap.
        inverted_errormap = OrderedDict()
        for law_id in errormap.keys():
            # Ignore errors that are not a part of the laws currently
            # being requested for processing.
            if law_id not in law_ids:
                continue

            error_msg = errormap[law_id]

            if error_msg:
                failures += 1
            else:
                # If there is no error, it's success.
                successes += 1
                continue

            if error_msg not in inverted_errormap:
                inverted_errormap[error_msg] = []

            inverted_errormap[error_msg].append(law_id)

        # Sort errors so that the most common ones are shown last.
        inverted_errormap = OrderedDict(sorted(
            inverted_errormap.items(),
            key=lambda x: len(x[1])
        ))

        width, height = terminal_width_and_height()
        for error_msg in inverted_errormap.keys():
            print()
            print('%s' % ('-' * width))
            print(error_msg)
            print('Errors: %d' % len(inverted_errormap[error_msg]))
            print()
            for law_id in inverted_errormap[error_msg]:
                print(' - %s' % law_id, end='')

        print()
        print('%s' % ('-' * width))
        print('Total: %d. Successes: %d. Failures: %d. Success ratio: %.2f%%.' % (
            successes + failures,
            successes,
            failures,
            100 * (successes / (successes + failures))
        ))


def usage(exec_name, message=None):
    print('Usage: %s [law_number>/<year>] [law_number>/<year>]...' % exec_name, file=stderr)
    print(file=stderr)
    print('Running without options or specific laws will process all available laws.', file=stderr)
    print(file=stderr)
    print('Options:', file=stderr)
    print('    --help              Display this help message.', file=stderr)
    print(file=stderr)
    print('    --try-broken        Try processing laws known to have failed.', file=stderr)
    print('    --single-thread     Skip multi-processing (mostly for debugging).', file=stderr)
    print(file=stderr)
    if message:
        print('Error: %s' % message, file=stderr)
    quit(1)


def main(argv):

    # A list of valid options so that we'll know when something is thrown in
    # that we don't know what to do with.
    valid_options = ['--help', '--try-broken', '--single-thread']

    if '--help' in argv:
        usage(argv[0])

    # Container for laws that are about to be processed.
    law_ids = []

    if '--try-broken' in argv:
        law_ids = get_broken_law_ids()
        if len(law_ids) == 0:
            print('Hooray! Nothing seems broken!')
            quit()
    else:
        # Add things in command line that match the pattern for a law_id.
        for arg in argv[1:]:
            if re.match(r'^\d{1,4}\/\d{4}$', arg):
                law_ids.append(arg)
            elif arg not in valid_options:
                usage(argv[0], 'Unknown option "%s"' % arg)

    # If nothing is selected, we'll process everything.
    if len(law_ids) == 0:
        law_ids = get_available_law_ids()

    # Sort the law_ids in their own special way (year first, num second).
    law_ids = sorted_law(law_ids)

    # This is apparently safer than `multiprocessing.cpu_count()`,
    # according to:
    # https://stackoverflow.com/questions/1006289/how-to-find-out-the-number-of-cpus-using-python
    cpu_count = len(os.sched_getaffinity(0))

    def init_pool():
        # Start ignoring the KeyboardInterrupt signal in the main thread. The
        # result is that it gets caught by the sub-processes, which **don't**
        # inherit this setting. The exception is then thrown when waiting for
        # the process pool to finish, and caught by the code running the
        # `main` function.
        signal.signal(signal.SIGINT, signal.SIG_IGN)

    with Pool(cpu_count, init_pool) as pool:
        if '--single-thread' in argv:
            # Multiprocessing has some wide-reaching implications for various
            # under-the-hood mechanics like debugging. We need the ability to
            # have those work, so we offer this option to sidestep threading.
            #
            # This is only "yield-ified" so that the results stay compatible
            # with the code that handles those same results when using
            # multiprocessing.
            def yieldify_processing(law_ids):
                for law_id in law_ids:
                    yield process_law(law_id)

            results = yieldify_processing(law_ids)
        else:
            # Start an asynchronous pool of processes, as many as there are
            # CPUS, giving them a list of the laws that need processing.
            results = pool.imap_unordered(process_law, law_ids)

        # Open the errormap for recording successes and errors.
        with open(ERRORMAP_FILENAME, 'r') as f:
            errormap = json.load(f, object_pairs_hook=OrderedDict)

        # Monitor and record return successes and errors. We'll want to record
        # the errormap, no matter what.
        try:

            # Initial state of iterator.
            i = 0

            # Let's only do this once.
            law_count = len(law_ids)

            # Keep doing this until we hit a StopIteration exception.
            while True:
                try:
                    # Catch next result.
                    law_id, error_trace = next(results)

                    # Remember in errormap (gets written later).
                    errormap[law_id] = error_trace

                    # Tell the user about it.
                    msg = 'done' if error_trace is None else 'failed'
                    report(law_id, i, law_count, msg)

                    # Increase iterator.
                    i += 1

                except StopIteration:
                    break
        finally:
            # Write the errormap.
            with open(ERRORMAP_FILENAME, 'w') as f:
                json.dump(errormap, f)

    # List the errors and identify laws in which they occurred.
    display_errors(law_ids)


try:
    main(sys.argv)
except KeyboardInterrupt:
    quit()
except Exception as e:
    if settings.DEBUG:
        raise
    else:
        print('Error: %s' % e, file=stderr)
